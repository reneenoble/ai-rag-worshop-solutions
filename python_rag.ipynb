{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets build an AI app!\n",
    "\n",
    "The following steps will cover:\n",
    "1. How to use GPT to create a chatbot in Python.\n",
    "2. How to add data to your own chatbot. \n",
    "3. Create a basic web app using GPT with your own data\n",
    "4. Create an improved web app that keeps track of the message history for improved context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get set up!\n",
    "\n",
    "To use GPT in this workshop we've set up a proxy that means you get easy access to Azure OpenAI services.\n",
    "\n",
    "To get access to the proxy service go to [this link](https://aka.ms/UTS-Tech-Fest-AI-Proxy) and sign in with your GitHub account.\n",
    "\n",
    "You will need the **key** and **endpoint** that you get from the proxy site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Make an AI chatbot in Python\n",
    "\n",
    "In this part you will get the key and end point and create the code to ask a question to Azure OpenAI service. \n",
    "\n",
    "### üåè Set up your environment\n",
    "1. Open the terminal using the top menu\n",
    "2. Set up a python virtual environment in the terminal with this command `python3 -m venv ai-app-env`\n",
    "3. Activate the virtual environment with this command `source ai-app-env/bin/activate`\n",
    "4. Run the next cell (the hello world code) and set your kernal for Jupyter notebooks, selected *\"Select Another Kernal\"* at the top to **ai-app-env** and click \"Install\" on the pop up.\n",
    "\n",
    "### üß† Add AI\n",
    "1. Go the the requirements.txt file and add `openai`\n",
    "2. In the terminal run the command `pip install -r requirements.txt`\n",
    "3. In the code snippet below import the OpenAIClient library at the top of the next code snippet like this: `from openai import AzureOpenAI`. \n",
    "4. In the text below fill in the key and endpoint in the variables `AOAI_ENDPOINT` and `AOAI_KEY` *(AOAI is short for Azure OpenAI)*\n",
    "5. In the section where the client is set up, set the following parameters:\n",
    "    - Set api_key to the AOAI_KEY constant you created\n",
    "    - Set azure_endpoint to the AOAI_ENDPOINT constant you created\n",
    "    - Set api_version to `\"2024-05-01-preview\"`\n",
    "5. Run you code with the play (triangle) button, *you may need to set your Python interpreter at the top.* \n",
    "\n",
    "### üó£Ô∏è Change the tone of the AI and the question\n",
    "1. You can make the tone of the chat different, make it talk like Elmo, a surf bro, or anything you like.\n",
    "2. Update the question variable to ask a different question.\n",
    "\n",
    "### üîÑ *Bonus: Ask more questions!* \n",
    "1. Create a `while True:` loop after the SYSTEM_MESSAGE variable is set. \n",
    "2. Use the `input` function to ask the user to input a question. Assign it to the question variable (instead of hard coding it like it currently is).\n",
    "3. Make sure all the question and AI related content is inside the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dude, the capital of France is Paris! It's like, totally famous for the Eiffel Tower, croissants, and the Louvre Museum where you can check out the Mona Lisa, man. It's a rad city with a lot of history and culture. If you want to learn more, you can check it out on the official website of the Paris Convention and Visitors Bureau, bro: https://en.parisinfo.com/\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# Put the keys and variables here (never put your real keys in the code)\n",
    "AOAI_ENDPOINT = \n",
    "AOAI_KEY = \n",
    "MODEL_NAME = \"gpt-35-turbo-16k\"\n",
    "\n",
    "# Set up the client for AI Chat\n",
    "client = AzureOpenAI(\n",
    "    api_key=AOAI_KEY,\n",
    "    azure_endpoint=AOAI_ENDPOINT,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")\n",
    "\n",
    "# Set the tone of the conversation\n",
    "# SYSTEM_MESSAGE = \"You are a helpful AI assistant that can answer questions and provide information. You can also provide sources for your information.\"\n",
    "SYSTEM_MESSAGE = \"You are an assistant that speaks like a surfer. You can answer questions and provide information. You can also provide sources for your information.\"\n",
    "\n",
    "# What question do you want to ask?\n",
    "question = \"What is the capital of France?\"\n",
    "\n",
    "# Create the message history\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "    {\"role\": \"user\", \"content\": question},\n",
    "]\n",
    "\n",
    "# Get the answer using the GPT model (create 1 answer (n) and use a temperature of 0.7 to set it to be pretty creative/random)\n",
    "response = client.chat.completions.create(model=MODEL_NAME,temperature=0.7,n=1,messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add data to your chatbot\n",
    "Our chatbot now knows how to read and to write and has some general purpose knowledge. But it doens't know about many specific resources or new resources (from after the model was trainied). We'll be adding some data that we can search through before it answers the question.\n",
    "\n",
    "### üåè‚ôªÔ∏è Upate your environment\n",
    "1. Copy your previous code into the Python cell below. \n",
    "2. Go to the requirements.txt file and add `azure-search-documents` and `azure-core`\n",
    "3. In the terminal run the command `pip install -r requirements.txt` again to install the new library in the list.\n",
    "4. At the top of your code import the libraries need to **search documents** and create **login credentials for Azure** like this\n",
    "    ```\n",
    "    from azure.search.documents import SearchClient\n",
    "    from azure.core.credentials import AzureKeyCredential\n",
    "    ```\n",
    "\n",
    "### üîé Add Search capabilties \n",
    "1. Add another constant called `SEARCH_ENDPOINT` and set it to the same things as your `AOAI_ENDPOINT` *(this is only the same because we are using the proxy service)*.\n",
    "2. Add another constant called `SEARCH_KEY` and set it to the same things as your `AOAI_KEY`.\n",
    "3. Add another constant called `AZURE_SEARCH_INDEX` and set it to one of the following strings, each is the name of an Azure Blob container *(I have uploaded relevant documents to the Azure Blob storage prior to the session. That is linked to the Azure AI Search resource)*:\n",
    "    - \"margiestravel\" - a fictional travel agency\n",
    "    - TODO\n",
    "    - TODO\n",
    "4. Copy this code and put it under where the AI Chat Client is set up:\n",
    "\n",
    "    ```\n",
    "    search_client = SearchClient(\n",
    "        endpoint=<PUT THE SEARCH ENDPOINT CONTSTANT HERE>,\n",
    "        credential=AzureKeyCredential(<ADD SEARCH KEY CONSTANT HERE>),\n",
    "        index_name=<PUT YOUR CHOSEN SEARCH INDEX HERE>,\n",
    "        )\n",
    "    ```\n",
    "5. Put in the variable names for the Search Endpoint, Search Key, and Search Index.\n",
    "\n",
    "### üîéüß† Use your AI Search Client\n",
    "1. After you have asked the user for a question, put this bit of code to query the AI Search resource. \n",
    "     `search_results = search_client.search(search_text=question)`\n",
    "2. On the next line add this code to join all of the results together into on big text hucnk:\n",
    "    `search_summary = \" \".join(result[\"content\"] for result in search_results)`\n",
    "3. Update the messages varaible so the user message looks like this (to include the search results):\n",
    "    `{\"role\": \"user\", \"content\": question + \"\\nSources: \" + search_results}`\n",
    "4. Run your code and ask a question that relates to the topic ou chose.\n",
    "\n",
    "### üìö *Bonus: Add more context with a message history* \n",
    "If you want to improve the quality of the results you can include the history of questions that have been asked. \n",
    "Work out how to build up the message list to include all the questions asked by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################################\n",
    "### Copy and paste your preious code here ###\n",
    "##############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris, dude! It's like totally known for the Eiffel Tower, the Louvre Museum, and all those tasty pastries. Check out this source from Margie's Travel Presents: www.margiestravel.com\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Put the keys and variables here (never put your real keys in the code)\n",
    "AOAI_ENDPOINT = \"https://polite-ground-030dc3103.4.azurestaticapps.net/api/v1\"\n",
    "AOAI_KEY = \"702a03df-3742-4136-bb82-c7b18b256ef5\"\n",
    "MODEL_NAME = \"gpt-35-turbo-16k\"\n",
    "AZURE_SEARCH_KEY = AOAI_KEY\n",
    "AZURE_SEARCH_ENDPOINT = AOAI_ENDPOINT\n",
    "AZURE_SEARCH_INDEX = \"margiestravel\"\n",
    "\n",
    "\n",
    "# Set up the client for AI Chat\n",
    "client = AzureOpenAI(\n",
    "    api_key=AOAI_KEY,\n",
    "    azure_endpoint=AOAI_ENDPOINT,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")\n",
    "search_client = SearchClient(\n",
    "    endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "    credential=AzureKeyCredential(AZURE_SEARCH_KEY),\n",
    "    index_name=AZURE_SEARCH_INDEX,\n",
    "    )\n",
    "\n",
    "\n",
    "# Set the tone of the conversation\n",
    "# SYSTEM_MESSAGE = \"You are a helpful AI assistant that can answer questions and provide information. You can also provide sources for your information.\"\n",
    "SYSTEM_MESSAGE = \"You are an assistant that speaks like a surfer. You can answer questions and provide information. You can also provide sources for your information.\"\n",
    "\n",
    "\n",
    "# What question do you want to ask?\n",
    "question = \"What is the capital of France?\"\n",
    "search_results = search_client.search(search_text=question)\n",
    "search_summary = \" \".join(result[\"content\"] for result in search_results)\n",
    "\n",
    "# Create the message history\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "    {\"role\": \"user\", \"content\": question + \"\\nSources: \" + search_summary},\n",
    "]\n",
    "\n",
    "# Get the answer using the GPT model (create 1 answer (n) and use a temperature of 0.7 to set it to be pretty creative/random)\n",
    "response = client.chat.completions.create(model=MODEL_NAME,temperature=0.7,n=1,messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Turn your Python script into an web app!\n",
    "\n",
    "## üåè‚ôªÔ∏è Update your environment\n",
    "1. Go to the requirements.txt file and add `Flask==3.0.3` and `requests` to the list\n",
    "2. In the terminal run the command `pip install -r requirements.txt` again to install the new library in the list.\n",
    "\n",
    "## üï∏Ô∏è Create your web app\n",
    "3. Go to the app.py file\n",
    "4. Copy in the the code from the above cell into the parts marked for imports, constants, and inside of the get_response function. \n",
    "5. Copy the following 2 routes in under the index route. \n",
    "\n",
    "    ```\n",
    "    # This is the route that shows the form the user asks a question on\n",
    "    @app.get('/test-ai')\n",
    "    def test_ai():\n",
    "        # Very basic form that sends a question to the /contextless-message endpoint\n",
    "        return \"\"\"\n",
    "        <h1>Ask a question!</h1>\n",
    "        <form method=\"post\" action=\"/test-ai\">\n",
    "            <textarea name=\"question\" placeholder=\"Ask a question\"></textarea>\n",
    "            <button type=\"submit\">Ask</button>\n",
    "        </form>\n",
    "        \"\"\"\n",
    "\n",
    "    # This is the route that the form sends the question to and sends back the response\n",
    "    @app.route(\"/test-ai\", methods=[\"POST\"])\n",
    "    def ask_response():\n",
    "        # Get the question from the form\n",
    "        question = request.form.get(\"question\")\n",
    "\n",
    "        # Return the response from the AI\n",
    "        return get_response(question)\n",
    "    ```\n",
    "## üëÄ Checkout your web app\n",
    "6. Run your code, this will start the web server.\n",
    "7. Click on the link/button to view the web page and navigate to the test-ai page from the hoem page. \n",
    "8. See if your AI is working!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3.b - A nicer AI question answers\n",
    "1. Add the following routes (under the other 3) to serve up the provided ask.html file with CSS. *(This uses JavaScript to return the form data in preparation for Part 4.)*\n",
    "    ```\n",
    "    @app.get('/ask')\n",
    "    def ask():\n",
    "        # return render_template('hello.html', name=request.args.get('name'))\n",
    "    return render_template(\"ask.html\")\n",
    "\n",
    "\n",
    "    @app.route('/contextless-message', methods=['GET', 'POST'])\n",
    "    def contextless_message():\n",
    "        question = request.json['message']\n",
    "        resp = get_response(question)\n",
    "        return {\"resp\": resp[0]}\n",
    "    ```\n",
    "2. Run your server again and go to the /ask route on the server. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Improve your app with a message history\n",
    "In this part we've provided a HTML template, JavaScript and CSS that handle the front end to have an ongoing conversation. \n",
    "Each time we will unpack both the question and the previous chat history (the context) from the JSON we receive in the request. \n",
    "\n",
    "1. Add these two routes to your app.py file under your other routes.\n",
    "    ```\n",
    "    @app.get('/chat')\n",
    "    def chat():\n",
    "    return render_template('chat.html')\n",
    "\n",
    "    @app.route(\"/context-message\", methods=[\"GET\", \"POST\"])\n",
    "    def context_message():\n",
    "        question = request.json[\"message\"]\n",
    "        context = request.json[\"context\"]\n",
    "\n",
    "        resp, context = get_response(question, context)\n",
    "        return {\"resp\": resp, \"context\": context}\n",
    "    ```\n",
    "\n",
    "2. Update your get_response function where you create the message variable, get rid of your existing message variable and replace it with this if statement. *(This will test if there is already a message history to add to or if one should be created.)*\n",
    "    ```\n",
    "    # Create a new message history if there isn't one\n",
    "    if not message_history:\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "            {\"role\": \"user\", \"content\": question + \"\\nSources: \" + search_summary},\n",
    "        ]\n",
    "    # Otherwise, append the user's question to the message history\n",
    "    else:\n",
    "        messages = message_history + [\n",
    "            {\"role\": \"user\", \"content\": question + \"\\nSources: \" + search_summary},\n",
    "        ]\n",
    "    ```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
